{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz41r9-4p57G"
      },
      "source": [
        "# BigQuery Release Note Notifier\n",
        "\n",
        "This notebook automates the process of identifying new BigQuery release notes, generating information to evaluate the new feature and learn more, and then posting the suggestions to a Google Chat space.\n",
        "\n",
        "This version is specifically designed for **Colab Enterprise** and uses Google Cloud's native authentication (ADC) and Secret Manager."
      ],
      "id": "Tz41r9-4p57G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzQ3My4Np57H"
      },
      "source": [
        "## ‚öôÔ∏è 1. Setup and Installation\n",
        "\n",
        "First, install the necessary Python libraries from PyPI."
      ],
      "id": "rzQ3My4Np57H"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tMd9w9Hop57H"
      },
      "outputs": [],
      "source": [
        "!pip install google-genai google-cloud-secret-manager google-cloud-bigquery python-dateutil beautifulsoup4 lxml --quiet"
      ],
      "id": "tMd9w9Hop57H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVwfi-dup57H"
      },
      "source": [
        "## üìö 2. Import Libraries"
      ],
      "id": "eVwfi-dup57H"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM3t82oVp57H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from dateutil import parser\n",
        "from bs4 import BeautifulSoup\n",
        "import hashlib\n",
        "import re\n",
        "\n",
        "# Import the necessary Google Cloud libraries\n",
        "from google import genai\n",
        "from google.genai.types import HttpOptions\n",
        "from google.cloud import secretmanager\n",
        "from google.cloud import bigquery"
      ],
      "id": "CM3t82oVp57H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlcTAVZJp57I"
      },
      "source": [
        "## ‚òÅÔ∏è 3. Configure Google Cloud Environment\n",
        "\n",
        "Initialize the Google Gen AI SDK. In Colab Enterprise, it will automatically use the project and credentials from the environment. Then, set the variables to retrieve your Google Chat webhook URL securely from Secret Manager."
      ],
      "id": "LlcTAVZJp57I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvAHuL_Kp57I"
      },
      "outputs": [],
      "source": [
        "# --- Configuration ---\n",
        "GCP_PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "CHAT_WEBHOOK_SECRET_ID = \"chat-webhook-url\"\n",
        "LOOKBACK_DAYS = 7\n",
        "BIGQUERY_DATASET_ID = \"release_note_tracker\"\n",
        "BIGQUERY_TABLE_ID = \"processed_features\"\n",
        "LOCATION = \"global\""
      ],
      "id": "jvAHuL_Kp57I"
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(vertexai=True, project=GCP_PROJECT_ID, location=LOCATION)\n",
        "model_id = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "WsC6ZHCw_81L"
      },
      "id": "WsC6ZHCw_81L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment out or delete this cell once Dataset is created\n",
        "!bq mk --location=US --dataset $GCP_PROJECT_ID:$BIGQUERY_DATASET_ID"
      ],
      "metadata": {
        "id": "cZ75oWoN5Xcc"
      },
      "id": "cZ75oWoN5Xcc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the DDL query using the variables\n",
        "ddl_query = f\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS `{GCP_PROJECT_ID}.{BIGQUERY_DATASET_ID}.{BIGQUERY_TABLE_ID}` (\n",
        "    feature_id STRING NOT NULL OPTIONS(description=\"A unique hash of the feature content to prevent duplicates\"),\n",
        "    published_date DATE OPTIONS(description=\"The publication date of the release note\"),\n",
        "    release_title STRING OPTIONS(description=\"The title of the parent release note\"),\n",
        "    feature_description STRING OPTIONS(description=\"The HTML content of the specific feature\"),\n",
        "    gemini_suggestion STRING OPTIONS(description=\"The suggestion generated by Gemini\"),\n",
        "    processing_timestamp TIMESTAMP NOT NULL OPTIONS(description=\"When the feature was processed by this notebook\")\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query using the bq command-line tool\n",
        "!bq query --nouse_legacy_sql '{ddl_query}'"
      ],
      "metadata": {
        "id": "cYGSSer06OpT"
      },
      "id": "cYGSSer06OpT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hPi1yrOp57I"
      },
      "outputs": [],
      "source": [
        "def get_secret(secret_id, project_id, version_id=\"latest\"):\n",
        "    \"\"\"\n",
        "    Retrieves a secret from Google Cloud Secret Manager.\n",
        "    \"\"\"\n",
        "    client = secretmanager.SecretManagerServiceClient()\n",
        "    name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
        "    try:\n",
        "        response = client.access_secret_version(request={\"name\": name})\n",
        "        return response.payload.data.decode(\"UTF-8\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error retrieving secret: {e}\")\n",
        "        print(\"Please ensure the secret exists and the service account has the 'Secret Manager Secret Accessor' role.\")\n",
        "        return None\n",
        "\n",
        "# Fetch the webhook URL at the start of the script.\n",
        "CHAT_WEBHOOK_URL = get_secret(CHAT_WEBHOOK_SECRET_ID, GCP_PROJECT_ID)"
      ],
      "id": "0hPi1yrOp57I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjn7DltQp57I"
      },
      "source": [
        "## üì∞ 4. Define Helper Functions"
      ],
      "id": "hjn7DltQp57I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5EZRawWp57I"
      },
      "outputs": [],
      "source": [
        "def get_recent_release_notes(days=1):\n",
        "    \"\"\"\n",
        "    Fetches BigQuery release notes, extracts individual features marked with\n",
        "    <h3>Feature</h3>, and returns each feature as a separate item.\n",
        "    \"\"\"\n",
        "    feed_url = \"https://cloud.google.com/feeds/bigquery-release-notes.xml\"\n",
        "    recent_features = [] # This list will hold individual features\n",
        "    time_threshold = datetime.now(timezone.utc) - timedelta(days=days)\n",
        "\n",
        "    print(f\"Fetching notes published after {time_threshold.strftime('%Y-%m-%d %H:%M:%S %Z')}...\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(feed_url)\n",
        "        response.raise_for_status()\n",
        "        root = ET.fromstring(response.content)\n",
        "        namespaces = {'atom': 'http://www.w3.org/2005/Atom'}\n",
        "\n",
        "        for entry in root.findall('atom:entry', namespaces):\n",
        "            date_element = entry.find('atom:published', namespaces)\n",
        "            if date_element is None:\n",
        "                date_element = entry.find('atom:updated', namespaces)\n",
        "\n",
        "            if date_element is not None:\n",
        "                published_str = date_element.text\n",
        "                published_date = parser.parse(published_str)\n",
        "\n",
        "                if published_date >= time_threshold:\n",
        "                    base_title = entry.find('atom:title', namespaces).text\n",
        "                    base_link = entry.find('atom:link', namespaces).get('href')\n",
        "                    base_published_date = published_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "                    content_element = entry.find('atom:summary', namespaces) or entry.find('atom:content', namespaces)\n",
        "                    html_content = content_element.text if content_element is not None else \"\"\n",
        "\n",
        "                    if not html_content:\n",
        "                        continue\n",
        "\n",
        "                    soup = BeautifulSoup(html_content, 'lxml')\n",
        "                    h3_tags = soup.find_all('h3')\n",
        "\n",
        "                    for h3 in h3_tags:\n",
        "                        # Process only if the h3 tag is for a \"Feature\"\n",
        "                        if h3.get_text(strip=True).lower() == 'feature':\n",
        "                            feature_html_parts = []\n",
        "                            # Collect all sibling tags after this h3 until the next h3\n",
        "                            for sibling in h3.find_next_siblings():\n",
        "                                if sibling.name == 'h3':\n",
        "                                    break # Stop when we hit the next section\n",
        "                                feature_html_parts.append(str(sibling))\n",
        "\n",
        "                            feature_description = \"\".join(feature_html_parts).strip()\n",
        "\n",
        "                            if feature_description:\n",
        "                                # Create a separate record for this specific feature\n",
        "                                recent_features.append({\n",
        "                                    'title': base_title,\n",
        "                                    'link': base_link,\n",
        "                                    'published': base_published_date,\n",
        "                                    'summary': feature_description\n",
        "                                })\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Error fetching the URL: {e}\")\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"‚ùå Error parsing the XML: {e}\")\n",
        "\n",
        "    return recent_features"
      ],
      "id": "Q5EZRawWp57I"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_use_cases(release_note):\n",
        "    \"\"\"\n",
        "    Generates onboarding suggestions for a new feature using Gemini.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    You are an AI assistant specialized in helping data analysts quickly understand and apply new technologies.\n",
        "    Your goal is to provide practical, actionable advice about the new BigQuery feature described below.\n",
        "\n",
        "    Instructions:\n",
        "    1.  **Where to Learn More:** Briefly suggest 1-2 key resources where an analyst can find detailed information or examples (e.g., official documentation, a specific tutorial, or a relevant blog post). Use the provided link as your primary source.\n",
        "    2.  **How to Investigate its Usefulness:** Outline three distinct and practical ways a data analyst can quickly determine if this new feature could be valuable to them.\n",
        "        - Frame these as concise \"Consider this if...\" or \"Try this if...\" scenarios that connect directly to common data analyst tasks and pain points.\n",
        "        - The goal is to prompt self-reflection on their current workflow, not to propose a full project.\n",
        "    -   Be direct and concise. Avoid conversational introductions or summaries.\n",
        "\n",
        "    *** NEW SECTION START ***\n",
        "    Formatting Instructions:\n",
        "    -   **You MUST format your entire response using simple HTML tags.**\n",
        "    -   Use `<b>` for bold headers (e.g., `<b>Where to Learn More:</b>`).\n",
        "    -   Use `<br>` for all line breaks.\n",
        "    -   Use `<a>` tags for any links.\n",
        "    -   Use \"‚Ä¢ \" (a bullet and a space) for bullet points, followed by a `<br>`.\n",
        "    -   Do NOT use Markdown (like `**`, `*`, or `- ` lists).\n",
        "    *** NEW SECTION END ***\n",
        "\n",
        "    Release Note Title: \"{release_note['title']}\"\n",
        "    Link to full note: {release_note['link']}\n",
        "\n",
        "    Feature to Analyze:\n",
        "    {release_note['summary']}\n",
        "\n",
        "    Generate the HTML-formatted actionable advice now.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(model=model_id,contents=prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error generating content with Gemini: {e}\")\n",
        "        print(\"Please ensure the Vertex AI API is enabled and the service account has the 'Vertex AI User' role.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ZYuJg08FuyrB"
      },
      "id": "ZYuJg08FuyrB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_processed_ids_from_bq(project_id, dataset_id, table_id):\n",
        "    \"\"\"Queries BigQuery to get the set of all feature_id's already processed.\"\"\"\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "    table_ref = f\"{project_id}.{dataset_id}.{table_id}\"\n",
        "    query = f\"SELECT feature_id FROM `{table_ref}`\"\n",
        "\n",
        "    try:\n",
        "        query_job = bq_client.query(query)\n",
        "        processed_ids = {row.feature_id for row in query_job}\n",
        "        print(f\"Loaded {len(processed_ids)} processed feature IDs from BigQuery.\")\n",
        "        return processed_ids\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not query BigQuery table. Assuming no prior history. Error: {e}\")\n",
        "        return set()"
      ],
      "metadata": {
        "id": "5sG_GipWxqOm"
      },
      "id": "5sG_GipWxqOm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_result_to_bq(project_id, dataset_id, table_id, feature_data):\n",
        "    \"\"\"Streams a new record into the BigQuery log table.\"\"\"\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "    table_ref = bq_client.dataset(dataset_id).table(table_id)\n",
        "\n",
        "    rows_to_insert = [feature_data] # The API expects a list of dictionaries\n",
        "\n",
        "    errors = bq_client.insert_rows_json(table_ref, rows_to_insert)\n",
        "    if not errors:\n",
        "        print(f\"Successfully saved feature {feature_data['feature_id']} to BigQuery.\")\n",
        "    else:\n",
        "        print(f\"‚ùå Error inserting rows to BigQuery: {errors}\")"
      ],
      "metadata": {
        "id": "VaqVrPdoxrPt"
      },
      "id": "VaqVrPdoxrPt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_gemini_html_for_chat(html_content):\n",
        "    \"\"\"\n",
        "    Converts complex HTML from Gemini into the limited HTML supported by Google Chat cards.\n",
        "\n",
        "    - Converts <h2>, <h3>, <strong> to <b>\n",
        "    - Converts <ul>/<li> into bulleted lists with <br>\n",
        "    - Converts <hr> to '---'\n",
        "    - Preserves <a> tags\n",
        "    \"\"\"\n",
        "    if not html_content:\n",
        "        return \"\"\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'lxml')\n",
        "\n",
        "    # 1. Replace headers (h2, h3, etc.) and <strong> with <b>\n",
        "    for tag in soup.find_all(['h2', 'h3', 'h4', 'strong']):\n",
        "        tag.name = 'b'\n",
        "        # Add a line break after headers for spacing\n",
        "        if tag.name in ['h2', 'h3', 'h4']:\n",
        "            tag.insert_after(soup.new_tag('br'))\n",
        "\n",
        "    # 2. Replace <hr>\n",
        "    for tag in soup.find_all('hr'):\n",
        "        tag.replace_with(BeautifulSoup('<br>---<br>', 'lxml'))\n",
        "\n",
        "    # 3. Process <ul>\n",
        "    for ul in soup.find_all('ul'):\n",
        "        # Add a line break before the list\n",
        "        ul.insert_before(soup.new_tag('br'))\n",
        "\n",
        "        list_items_html = \"\"\n",
        "        for li in ul.find_all('li'):\n",
        "            # Get the inner content of li (which might include <a> tags)\n",
        "            inner_html = li.decode_contents().strip()\n",
        "            list_items_html += f\"‚Ä¢ {inner_html}<br>\"\n",
        "\n",
        "        # Replace the <ul> tag with the new HTML string, parsed by BS\n",
        "        ul.replace_with(BeautifulSoup(list_items_html, 'lxml'))\n",
        "\n",
        "    # 4. Handle <p> tags by just adding a line break after them and removing the tag\n",
        "    for p in soup.find_all('p'):\n",
        "        p.insert_after(soup.new_tag('br'))\n",
        "        p.unwrap() # Remove the <p> tag itself, leaving content\n",
        "\n",
        "    # 5. Get the final string.\n",
        "    # We decode the contents of the body (if it exists) to avoid <html><body> tags\n",
        "    if soup.body:\n",
        "        formatted_html = soup.body.decode_contents()\n",
        "    else:\n",
        "        formatted_html = soup.decode_contents()\n",
        "\n",
        "    # 6. Clean up potential excessive line breaks\n",
        "    formatted_html = re.sub(r'(<br\\s*/?>\\s*){2,}', '<br>', formatted_html)\n",
        "\n",
        "    return formatted_html.strip()"
      ],
      "metadata": {
        "id": "i4DeClqNEXSx"
      },
      "id": "i4DeClqNEXSx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fq6_oqwp57I"
      },
      "outputs": [],
      "source": [
        "def send_to_google_chat(feature_description, gemini_suggestion, published_date, link_url):\n",
        "    \"\"\"\n",
        "    Sends a formatted card message to a Google Chat space using a webhook.\n",
        "    \"\"\"\n",
        "    if not CHAT_WEBHOOK_URL:\n",
        "        print(\"‚ùå Google Chat webhook URL was not retrieved from Secret Manager. Cannot send message.\")\n",
        "        return\n",
        "\n",
        "    # --- 1. Clean the inputs for Google Chat Card formatting ---\n",
        "\n",
        "    # Strip all HTML tags from the feature description to get plain text\n",
        "    soup = BeautifulSoup(feature_description, 'lxml')\n",
        "    cleaned_description = soup.get_text(separator=\" \", strip=True)\n",
        "\n",
        "    # Optional: Truncate the description if it's too long\n",
        "    if len(cleaned_description) > 400:\n",
        "        cleaned_description = cleaned_description[:400] + \"...\"\n",
        "\n",
        "    # Convert Gemini's rich HTML into Chat-compatible HTML\n",
        "    formatted_suggestion = format_gemini_html_for_chat(gemini_suggestion)\n",
        "\n",
        "    # --- 2. Build the card with multiple widgets ---\n",
        "\n",
        "    # Each item in this list is a separate widget in the card section\n",
        "    widgets = [\n",
        "        {\n",
        "            \"textParagraph\": {\n",
        "                \"text\": f\"<b>New BigQuery Feature Published:</b><br>{cleaned_description}\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"textParagraph\": {\n",
        "                \"text\": f\"{formatted_suggestion}\"\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"buttonList\": {\n",
        "                \"buttons\": [\n",
        "                    {\n",
        "                        \"text\": \"View Release Note\",\n",
        "                        \"onClick\": {\n",
        "                            \"openLink\": {\n",
        "                                \"url\": link_url\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # --- 3. Build the full message body ---\n",
        "    message_body = {\n",
        "        'cardsV2': [{\n",
        "            'cardId': 'release-note-suggestion-card',\n",
        "            'card': {\n",
        "                'header': {\n",
        "                    'title': 'New BQ Feature & Onboarding Suggestions!',\n",
        "                    'subtitle': f\"Published on: {published_date}\",\n",
        "                    'imageUrl': 'https://cloud.google.com/images/social-icon-google-cloud-1200-630.png',\n",
        "                    'imageType': 'CIRCLE'\n",
        "                },\n",
        "                'sections': [{\n",
        "                    'widgets': widgets  # <-- Use the list of widgets here\n",
        "                }]\n",
        "            }\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    headers = {'Content-Type': 'application/json; charset=UTF-8'}\n",
        "    try:\n",
        "        response = requests.post(CHAT_WEBHOOK_URL, data=json.dumps(message_body), headers=headers)\n",
        "        response.raise_for_status()\n",
        "        print(\"‚úÖ Card message sent to Google Chat successfully.\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"‚ùå Error sending message to Google Chat: {e}\")"
      ],
      "id": "_fq6_oqwp57I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuhWYHEPp57I"
      },
      "source": [
        "## üöÄ 5. Run the Main Workflow\n",
        "\n",
        "This final cell executes the entire process: fetch notes, generates suggestions, and send notifications."
      ],
      "id": "YuhWYHEPp57I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-QG_UkPp57I"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Orchestrates the entire process: fetch, generate, log, and send.\n",
        "    \"\"\"\n",
        "    print(f\"üöÄ Starting BigQuery launch check for the last {LOOKBACK_DAYS} day(s)...\")\n",
        "\n",
        "    # Load the IDs of features we've already processed from BigQuery\n",
        "    processed_ids = get_processed_ids_from_bq(GCP_PROJECT_ID, BIGQUERY_DATASET_ID, BIGQUERY_TABLE_ID)\n",
        "\n",
        "    all_recent_features = get_recent_release_notes(days=LOOKBACK_DAYS)\n",
        "\n",
        "    # Filter out features that have already been processed\n",
        "    new_features_to_process = []\n",
        "    for feature in all_recent_features:\n",
        "        # Create a unique, repeatable ID for each feature based on its content\n",
        "        feature_hash = hashlib.md5(feature['summary'].encode()).hexdigest()\n",
        "        feature['id'] = f\"{feature['published']}-{feature_hash}\"\n",
        "\n",
        "        if feature['id'] not in processed_ids:\n",
        "            new_features_to_process.append(feature)\n",
        "\n",
        "    if not new_features_to_process:\n",
        "        print(f\"‚úÖ No new, unprocessed features found. All done.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(new_features_to_process)} new feature(s) to process.\")\n",
        "\n",
        "    for i, launch in enumerate(new_features_to_process):\n",
        "        print(f\"\\n[{i+1}/{len(new_features_to_process)}] Processing feature: {launch['id']}\")\n",
        "        use_case_ideas = generate_use_cases(launch)\n",
        "\n",
        "        if use_case_ideas:\n",
        "            # First, send the notification to Google Chat\n",
        "            send_to_google_chat(\n",
        "                feature_description=launch['summary'],\n",
        "                gemini_suggestion=use_case_ideas,\n",
        "                published_date=launch['published'],\n",
        "                link_url=launch['link']\n",
        "            )\n",
        "\n",
        "            # Then, prepare the data and log the result to BigQuery\n",
        "            record = {\n",
        "                \"feature_id\": launch['id'],\n",
        "                \"published_date\": launch['published'],\n",
        "                \"release_title\": launch['title'],\n",
        "                \"feature_description\": launch['summary'],\n",
        "                \"gemini_suggestion\": use_case_ideas,\n",
        "                \"processing_timestamp\": datetime.now(timezone.utc).isoformat()\n",
        "            }\n",
        "            save_result_to_bq(GCP_PROJECT_ID, BIGQUERY_DATASET_ID, BIGQUERY_TABLE_ID, record)\n",
        "\n",
        "    print(\"\\nüéâ Workflow complete.\")"
      ],
      "id": "M-QG_UkPp57I"
    },
    {
      "cell_type": "code",
      "source": [
        "#Run main\n",
        "main()"
      ],
      "metadata": {
        "id": "Pe8gBsd8x2Fk"
      },
      "id": "Pe8gBsd8x2Fk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "name": "bq_releases_chat_notification"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}